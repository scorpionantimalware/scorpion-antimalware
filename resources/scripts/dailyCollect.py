#!/usr/bin/env python3

# this is to collect the dailyor hourly malware samples from malware bazaar
import argparse
import requests
from bs4 import BeautifulSoup
import os
from urllib.parse import urlparse, urljoin
from mimetypes import guess_extension

def download_links_page(url, download_folder):
  # Send a GET request to the URL
    response = requests.get(url)

    # Check if the request was successful (status code 200)
    if response.status_code == 200:
        # Parse the HTML content using BeautifulSoup
        soup = BeautifulSoup(response.text, 'html.parser')

        # Create the download folder if it doesn't exist
        os.makedirs(download_folder, exist_ok=True)

        # Download each link that points to a file
        for link in soup.find_all('a', href=True):
            link_url = urljoin(url, link['href'])

            # Determine the file name from the URL
            file_name = os.path.basename(urlparse(link_url).path)

            # Check if the link points to a file
            if '.' in file_name:
                # Download the file
                try:
                    with requests.get(link_url, stream=True) as r:
                        r.raise_for_status()
                        
                        # Determine the file extension based on MIME type
                        extension = guess_extension(r.headers['Content-Type'])
                        if extension:
                            file_name = f"{file_name}{extension}"

                        with open(os.path.join(download_folder, file_name), 'wb') as f:
                            for chunk in r.iter_content(chunk_size=8192):
                                f.write(chunk)
                    print(f"Downloaded: {link_url}")
                except requests.exceptions.RequestException as e:
                    print(f"Error downloading {link_url}: {e}")

    else:
        print(f"Failed to retrieve the page. Status code: {response.status_code}")


parser = argparse.ArgumentParser(description='Download a malware sample from Malware Bazaar')
parser.add_argument('-f', '--folder', help='the path to the download folder ', metavar="Download Folder", required=True, type=argparse.FileType('r'))
parser.add_argument('-s', '--selector', help='Selector type you want', type=str, metavar="SELECTOR", required=True, choices=['daily', 'hourly'])
# parser.add_argument('-u', '--unzip', help='Unzip the downloaded file', required=False, default=False, action='store_true') ## TODO: add this option

args = parser.parse_args()

folder = args.folder.name
selector = args.selector

if selector == 'daily':
    url_to_download = 'https://datalake.abuse.ch/malware-bazaar/daily/'
elif selector == 'hourly':
    url_to_download = 'https://datalake.abuse.ch/malware-bazaar/hourly/'

download_folder = 'downloaded_files'
download_links_page(url_to_download, download_folder)
