###################################################################################
#                                                                                 #
# fim.py                                                                          #
#                                                                                 #
###################################################################################
#                                                                                 #
#    Scorpion Anti-malware is a free Open Source AI-powered Anti-malware          #
#    framework for Researchers.                                                   #
#                                                                                 #
#    Copyright (c) 2024-present  (see AUTHORS.md).                                #
#                                                                                 #
#    This program is free software: you can redistribute it and/or modify         #
#    it under the terms of the GNU General Public License as published by         #
#    the Free Software Foundation, either version 3 of the License, or            #
#    (at your option) any later version.                                          #
#                                                                                 #
#    This program is distributed in the hope that it will be useful,              #
#    but WITHOUT ANY WARRANTY; without even the implied warranty of               #
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the                #
#    GNU General Public License for more details.                                 #
#                                                                                 #
#    You should have received a copy of the GNU General Public License            #
#    along with this program.  If not, see <https://www.gnu.org/licenses/>.       #
#                                                                                 #
###################################################################################

#!/usr/bin/env python3

import os
import sys
import pickle 
import datetime
import hashlib	
import logging
import time 
import dictdiffer 
# from progress.bar import Bar
import xml.etree.ElementTree as ET
from time import sleep
import threading
from typing import List

# Constants for log and storage files
# ALERT_FILE = 'alert.log'
# SCAN_STORAGE = 'hashes.pkl'
# LOG_FILE = 'handler.log'
# list_to_ignore = [SCAN_STORAGE, LOG_FILE, ALERT_FILE]

# Colors for terminal output (optional)
red = "\033[0;31m"
white = "\033[0;37m"

# Custom exception for no directories to monitor
class NoDirectoriesToMonitorError(Exception):
    pass

# # Custom exception for no directories to monitor
# class NoDirectoriesToMonitorError(Exception):
#     pass

# custom exception for if the frequency len is begger than 1
class FrequencyError(Exception):
    pass

# Read the XML config file to get directories to monitor
def read_config_file(file):
    # Initialize lists to store directories, frequency, and attributes
    directories = []
    frequency = []
    attributes = []

    try:
        tree = ET.parse(file)
        root = tree.getroot()

        for child in root:
            if child.tag == "Directory":
                directories.append(child.text.strip())
            elif child.tag == "scanInterval":
                frequency.append(child.text.strip())
            elif child.tag == "fileAttribute":
                attributes.append(child.text.strip())
    except Exception as e:
        print("Error in reading the config file")
        print(e)
        return directories, frequency, attributes
    return directories, frequency, attributes

# Count all files in the directory and its subdirectories
def count(scan_dir, list_to_ignore):
    var = 0
    for dir_name, _, file_list in os.walk(scan_dir):
        if list_to_ignore:
            for file in file_list:
                if file in list_to_ignore:
                    continue
                else:
                    var += 1
    return var

# Scan files in the directory
def scan_files(scan_dir, list_to_ignore):
    files = {}
    try:
        nignored_file_list = []
        for dir_name, _, file_list in os.walk(scan_dir):
            if list_to_ignore:
                for file in file_list:
                    if file in list_to_ignore:
                        continue
                    else:
                        nignored_file_list.append(file) 
            files[str(dir_name)] = nignored_file_list

        return files
    except Exception as e:
        logging.exception("Error in scanning files and dirs!")
        return files

# Save hashes to a file
def save_hash(list, file):
    try:
        with open(file, "wb") as f:
            pickle.dump(list, f)
    except Exception as e:
        logging.exception("Error while saving the dictionary")

# Load dictionary of hashes from a file
def load_dict(file):
    try:
        with open(file, 'rb') as f:
            return pickle.load(f)
    except Exception as e:
        logging.exception("Error while loading the dictionary")
        return {}

# Log events
def log(log_dir, message):
    current_dt = datetime.datetime.now()
    with open(log_dir, "a+") as f:
        f.write(f"{message} --- Time: {current_dt.strftime('%Y-%m-%d %H:%M:%S')}\n")

# Log changes
def log_change(log_dir, message):
    current_dt = datetime.datetime.now()
    with open(log_dir, "a+") as f:
        f.write(f"{message} --- Time: {current_dt.strftime('%Y-%m-%d %H:%M:%S')}\n")
    print(f"{red}{message}{white}")

# Calculate SHA256 hash of a file
def calculate_hash(file_path):
    try:
        sha256_hash = hashlib.sha256()
        with open(file_path, "rb") as f:
            for byte_block in iter(lambda: f.read(4096), b""):
                sha256_hash.update(byte_block)
        return sha256_hash.hexdigest()
    except Exception as e:
        logging.exception("Error while taking the hash values")
        return ""
    
# return the file size
def file_size(file_path):
    try:
        return os.path.getsize(file_path)
    except Exception as e:
        logging.exception("Error while taking the file size")
        return ""

#return the file owner
def file_owner(file_path):
    try:
        return os.stat(file_path).st_uid
    except Exception as e:
        logging.exception("Error while taking the file owner")
        return ""
    
#return the file group
def file_group(file_path):
    try:
        return os.stat(file_path).st_gid
    except Exception as e:
        logging.exception("Error while taking the file group")
        return ""
    
#return the file permissions    
def file_permissions(file_path):
    try:
        return os.stat(file_path).st_mode
    except Exception as e:
        logging.exception("Error while taking the file permissions")
        return ""

#return the file creation time
def file_creation_time(file_path):
    try:
        return os.path.getctime(file_path)
    except Exception as e:
        logging.exception("Error while taking the file creation time")
        return ""

#return the file modification time
def file_modification_time(file_path):
    try:
        return os.path.getmtime(file_path)
    except Exception as e:
        logging.exception("Error while taking the file modification time")
        return ""

#return the file access time
def file_access_time(file_path):
    try:
        return os.path.getatime(file_path)
    except Exception as e:
        logging.exception("Error while taking the file access time")
        return ""

def extract_file_hashes(file_info):
    """
    Extracts file paths and their corresponding hashes from the given dictionary.

    :param file_info: A dictionary containing file information.
    :return: A dictionary with file paths as keys and their hashes as values.
    """
    result = {}
    for file_path, info in file_info.items():
        result[file_path] = info['hash']
    return result


# Scan the directory tree and take hash of the files
def scan(scan_directory, list_to_ignore, attributes):
    directories = scan_files(scan_directory, list_to_ignore)
    file_metadata = {}

    for path, files in directories.items():
        for file in files:
            file_dir = os.path.join(path, file)
            file_info = {}

            if "check_256sum" in attributes or "check_all" in attributes:
                file_info['hash'] = calculate_hash(file_dir)
            if "check_size" in attributes or "check_all" in attributes:
                file_info['size'] = file_size(file_dir)
            if "check_owner" in attributes or "check_all" in attributes:
                file_info['owner'] = file_owner(file_dir)
            if "check_group" in attributes or "check_all" in attributes:
                file_info['group'] = file_group(file_dir)
            if "check_perm" in attributes or "check_all" in attributes:
                file_info['permissions'] = file_permissions(file_dir)
            if "check_ctime" in attributes or "check_all" in attributes:
                file_info['creation_time'] = file_creation_time(file_dir)
            if "check_mtime" in attributes or "check_all" in attributes:
                file_info['modification_time'] = file_modification_time(file_dir)
            if "check_atime" in attributes or "check_all" in attributes:
                file_info['access_time'] = file_access_time(file_dir)
    
            file_metadata[file_dir] = file_info
    

    return file_metadata 

def init_integrity(base_path: str, scan_directory: str, attributes: List[str]):
    directory_name = os.path.basename(scan_directory.rstrip(os.sep))
    alert_file = f'{base_path}/alert_{directory_name}.log'
    scan_storage = f'{base_path}/hashes_{directory_name}.pkl'
    log_file = f'{base_path}/handler_{directory_name}.log'
    list_to_ignore = [scan_storage, log_file, alert_file]

    print(f"DIRECTORY TO MONITOR: {scan_directory}")

    log(log_file, "Starting the initial scan...")

    initial_file_attrs = scan(scan_directory, list_to_ignore, attributes)
    init_hashes = extract_file_hashes(initial_file_attrs)
    

    # save the file hashes to a file
    save_hash(init_hashes, scan_storage)
    log(log_file, "Initial scan completed!")

    log(log_file, "Starting the integrity check...")

    return list_to_ignore, alert_file, scan_storage

# Integrity function to monitor directory changes
def integrity(scan_directory: str, attributes: List[str], list_to_ignore: List[str], scan_storage: str, alert_file: str, output_buffer: List[str]):
    new_attrs = scan(scan_directory, list_to_ignore, attributes)
    new_hash = extract_file_hashes(new_attrs)
    old_hash = load_dict(scan_storage)

    for diff in dictdiffer.diff(old_hash, new_hash):
        current_dt = datetime.datetime.now()

        action, path, details = diff

        if len(path) == 0:
            continue

        if action == 'add':
            file_path, new_hash = details[0]
            action_type = action
            old_hash = None

            output_buffer.append(file_path)
            output_buffer.append(action_type)
            output_buffer.append(new_hash)
            output_buffer.append(old_hash)
            output_buffer.append(f"Time: {current_dt.strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        elif action == 'change':
            file_path = path[0]
            old_hash, new_hash = details
            action_type = action

            output_buffer.append(file_path)
            output_buffer.append(action_type)
            output_buffer.append(new_hash)
            output_buffer.append(old_hash)
            output_buffer.append(f"Time: {current_dt.strftime('%Y-%m-%d %H:%M:%S')}\n")

        elif action == 'remove':
            file_path, old_hash = details[0]
            action_type = action
            new_hash = None

            output_buffer.append(file_path)
            output_buffer.append(action_type)
            output_buffer.append(new_hash)
            output_buffer.append(old_hash)
            output_buffer.append(f"Time: {current_dt.strftime('%Y-%m-%d %H:%M:%S')}\n")

        print(output_buffer)

    save_hash(new_hash, scan_storage)

# # Main execution
# if __name__ == "__main__":
#     #delete uneded files
#     # os.remove("/mnt/d/School/gradproject/scorpion-antimalware/sam-engine/FIM/scripts/handler_test.log")
#     # os.remove("/mnt/d/School/gradproject/scorpion-antimalware/sam-engine/FIM/scripts/hashes_test.pkl")

#     scan_directories, frequency, attributes  = read_config_file('fim_config.xml')
#     if len(scan_directories) == 0:
#         raise NoDirectoriesToMonitorError(f"{red}No directories to monitor{white}")

#     # Make sure that all directories exist
#     for directory in scan_directories:
#         if not os.path.exists(directory):
#             print(f"Directory {red}{directory} does not exist!{white}")
            
#     # Dealing with the frequency    
#     if len(frequency) > 1:
#         raise FrequencyError(f"{red}The frequency should be only one value!!!{white}")
#     elif len(frequency) == 1:
#         frequency = frequency[0]
#         if frequency == "realtime":
#             frequency = 4

#     # record the file attributes that we want to monitor
#     if len(attributes) == 0:
#         attribute = "check_all"
#     #else we already store the attribute in a list

#     stop_event = threading.Event()
#     threads = []
#     # Create and start a thread for each directory
#     for scan_directory in scan_directories:
#         list_to_ignore, alert_file, scan_storage = init_integrity("", scan_directory, attributes)
#         integrity_thread = threading.Thread(target=integrity, args=(scan_directory, attributes, list_to_ignore, scan_storage, alert_file))
#         integrity_thread.start()
#         threads.append(integrity_thread)
#         sleep(0.5)

#     try:
#         while True:
#             sleep(1)
#     except KeyboardInterrupt:
#         print("Stopping threads...")
#         stop_event.set()
#         for t in threads:
#             t.join()
#         print("All threads stopped.")








