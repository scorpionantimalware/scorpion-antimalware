import os
import math
import numpy as np
from glob import glob
import ImageProcessing
from keras.metrics import Precision, Recall
from keras import layers, models, optimizers
from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau
import tensorflow as tf

def build_cnn(image_height=256, image_width=256):
    m11 = models.Sequential()
    #m11.add(layers.experimental.preprocessing.Rescaling(1/home/user/projects/255, input_shape=(self.image_width, self.image_height, 1)))

    m11.add(layers.Conv2D(32, 3, padding='same', activation='relu',input_shape=(image_height, image_width, 1)))
    m11.add(layers.BatchNormalization())

    m11.add(layers.Conv2D(32, 3, padding='same', activation='relu'))
    m11.add(layers.BatchNormalization())
    m11.add(layers.MaxPooling2D())
    m11.add(layers.Dropout(.2))

    m11.add(layers.Conv2D(32, 3, padding='same', activation='relu'))
    m11.add(layers.BatchNormalization())
    m11.add(layers.Conv2D(32, 3, padding='same', activation='relu'))
    m11.add(layers.BatchNormalization())
    m11.add(layers.MaxPooling2D())
    m11.add(layers.Dropout(.3, input_shape=(2,)))

    m11.add(layers.Conv2D(32, 3, padding='same', activation='relu'))
    m11.add(layers.BatchNormalization())
    m11.add(layers.Conv2D(32, 3, padding='same', activation='relu'))
    m11.add(layers.BatchNormalization())
    m11.add(layers.MaxPooling2D())
    m11.add(layers.Dropout(.4, input_shape=(2,)))

    m11.add(layers.Flatten())
    m11.add(layers.Dense(4096, activation='relu'))
    m11.add(layers.BatchNormalization())
    m11.add(layers.Dropout(.2))
    m11.add(layers.Dense(4096, activation='relu'))
    m11.add(layers.BatchNormalization())
    m11.add(layers.Dropout(.3, input_shape=(2,)))
    m11.add(layers.BatchNormalization())
    m11.add(layers.Dense(4096, activation='relu'))
    m11.add(layers.BatchNormalization())
    m11.add(layers.Dropout(.4, input_shape=(2,)))
    m11.add(layers.Dense(1, activation='sigmoid'))
    return m11


def from_exe_to_img(exe_dir, out_dir, colormap_dir, width=512, only_exe=True):
      
    colormap = np.load(colormap_dir)
    
    if not os.path.exists(out_dir):
        os.mkdir(out_dir) 
    if only_exe:
        exe_names = glob('*.exe', root_dir=exe_dir)
    else:
        exe_names = glob('*', root_dir=exe_dir)
    
    img_count=0
    for file in exe_names:
        img_bin_array = ImageProcessing.readBytes(os.path.join(exe_dir, file) )
        grayscale_array = ImageProcessing.to1DArray_grayscale(img_bin_array, colormap)
        height = math.ceil(len(grayscale_array)/width)
        
        no_exe_name = os.path.splitext(file)[0]
        is_saved = ImageProcessing.saveImg(os.path.join(out_dir, no_exe_name+'.png'), grayscale_array, (width,height),'L')
        
        if is_saved:
            img_count += 1
            if(img_count%100==0):
                print(str(img_count)+ ": Done")
                
    return img_count


def bb_callbacks(outdir, name='cnn_cp'):
    checkpoint_cb = ModelCheckpoint(outdir+"/"+name+"_weights.keras", monitor='val_loss',
                                    verbose=1, save_best_only=True, mode='min',
                                    save_weights_only=True, save_freq='epoch')
    
    rlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7, verbose=1)

    early_stopping_cb = EarlyStopping(monitor="val_loss", min_delta=0, patience=10,
                                      verbose=1, mode="min", baseline=None,
                                      start_from_epoch=0, restore_best_weights=True)

    logger_cb = CSVLogger(outdir+"/"+name+"_log.csv", separator=",", append=False)

    return [checkpoint_cb, rlrop, early_stopping_cb, logger_cb]


def train_cnn_detector(model, training_set, validation_set, outdir, model_name='cnn_cp', epochs=30, batch_size=64, lr=0.001):
    
    if not os.path.exists(outdir):
        os.mkdir(outdir)
    
    model.compile(optimizer=optimizers.Adam(lr), loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall()])

    history = model.fit(training_set, epochs= epochs,
                        validation_data=validation_set, shuffle=True,
                        callbacks=bb_callbacks(outdir, model_name), batch_size=batch_size)

    # model.save(outdir+'/cnn_trained_30ep.keras')
    return history


def get_list_of_paths_and_labels(dirs_list:list, labels_list:list, search_type='png'):
    typee = '*.' + search_type
    if len(dirs_list) != len(labels_list):
        raise Exception("Incompatible dirs_list and labels_list lengths")
    
    if type(labels_list) != list or type(dirs_list) != list:
        raise Exception("dirs_list and labels_list must be of list type")
    
    filenames = []
    labels = []
    for dir, label in zip(dirs_list, labels_list):
        files_paths = glob(os.path.join(dir,typee))
        filenames = filenames + files_paths
        labels = labels + [label]*len(files_paths)
        
    return filenames, labels


def data_pipeline(input:tuple, parse_function, batch_size, shuffle, seed, reshuffle_each_iteration):
  with tf.device('/cpu:0'):
    data_set = tf.data.Dataset.from_tensor_slices(input)
    if shuffle:
      data_set = data_set.shuffle(len(input[0]), seed=seed, reshuffle_each_iteration=reshuffle_each_iteration)
      
    data_set = data_set.map(parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    data_set = data_set.batch(batch_size)
    data_set = data_set.prefetch(tf.data.experimental.AUTOTUNE)
  return data_set


# def upload_imgs(imgs_dir, is_mal, image_height=256, image_width=256, validation_size=0.3, seed=42):
#     b_len = len(os.listdir(imgs_dir))
#     parent_dir = os.path.dirname(imgs_dir)
#     ben_training_set = tf.keras.utils.image_dataset_from_directory(parent_dir, labels=[is_mal]*b_len,
#                                                             label_mode='int', color_mode='grayscale',
#                                                             batch_size=None, image_size=(image_height,image_width),
#                                                             seed=seed, validation_split=validation_size,
#                                                             interpolation="area",
#                                                             subset='training')

#     ben_validation_set = tf.keras.utils.image_dataset_from_directory(parent_dir, labels=[is_mal]*b_len,
#                                                            label_mode='int', color_mode='grayscale',
#                                                            batch_size=None, seed=seed, validation_split=validation_size,
#                                                            interpolation="area",
#                                                            subset='validation', image_size=(image_height,image_width))
    
#     return ben_training_set, ben_validation_set, b_len


# def concatenate_unbatched_sets(ben_training_set, ben_validation_set, b_len, mal_training_set, mal_validation_set, m_len,
#                     validation_size=0.3, seed=42):
#     training_set = ben_training_set.concatenate(mal_training_set)
#     # training_set = training_set.unbatch()
#     training_set = training_set.shuffle(int(((1-validation_size))*(b_len+m_len)), seed=seed)
#     # training_set = training_set.batch(batch_size)

#     validation_set = ben_validation_set.concatenate(mal_validation_set)
#     # validation_set = validation_set.unbatch()
#     validation_set = validation_set.shuffle(int((validation_size)*(b_len+m_len)), seed=seed)
#     # validation_set = validation_set.batch(batch_size)
    
#     return training_set, validation_set
    